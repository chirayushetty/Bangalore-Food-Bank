{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KpYTHMjcIpRL"
      },
      "source": [
        "<h2>Libraries</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "70nBFLDY0kcP"
      },
      "outputs": [],
      "source": [
        "#importing the libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import nltk\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Input, Embedding, LSTM , Dense,GlobalMaxPooling1D,Flatten\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPFKzVKQIpRN"
      },
      "source": [
        "<h2> Importing the Data </h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Rvgn3orx0sAJ"
      },
      "outputs": [],
      "source": [
        "#importing the dataset\n",
        "with open('data.json') as content:\n",
        "  data1 = json.load(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PGGvrVhl07o8"
      },
      "outputs": [],
      "source": [
        "#getting all the data to lists\n",
        "tags = []\n",
        "inputs = []\n",
        "responses={}\n",
        "for intent in data1['intents']:\n",
        "  responses[intent['tag']]=intent['responses']\n",
        "  for lines in intent['input']:\n",
        "    inputs.append(lines)\n",
        "    tags.append(intent['tag'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ruibWXd_3xFR"
      },
      "outputs": [],
      "source": [
        "#converting to dataframe\n",
        "data = pd.DataFrame({\"inputs\":inputs,\n",
        "                     \"tags\":tags})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "elc0th634mTr",
        "outputId": "a17be1cf-1a92-42cc-98fd-ae77795a0636"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     inputs        tags\n",
              "0                                     hello    greeting\n",
              "1                                  hi there    greeting\n",
              "2                          nice to meet you    greeting\n",
              "3    hi, is this is the Banglore Food Bank?    greeting\n",
              "4                             Anyone here ?    greeting\n",
              "..                                      ...         ...\n",
              "116                     Your achievements ?  statistics\n",
              "117          Where have you worked before ?  statistics\n",
              "118                    Your contributions ?  statistics\n",
              "119            Where have you contributed ?  statistics\n",
              "120                   How have you helped ?  statistics\n",
              "\n",
              "[121 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfb95ff7-8d8d-4c69-878b-49821b4fcade\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hello</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hi there</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nice to meet you</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hi, is this is the Banglore Food Bank?</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Anyone here ?</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>Your achievements ?</td>\n",
              "      <td>statistics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>Where have you worked before ?</td>\n",
              "      <td>statistics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>Your contributions ?</td>\n",
              "      <td>statistics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>Where have you contributed ?</td>\n",
              "      <td>statistics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>How have you helped ?</td>\n",
              "      <td>statistics</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfb95ff7-8d8d-4c69-878b-49821b4fcade')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cfb95ff7-8d8d-4c69-878b-49821b4fcade button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cfb95ff7-8d8d-4c69-878b-49821b4fcade');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#printing the data\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xd5Z3_oFf7iA"
      },
      "outputs": [],
      "source": [
        "data = data.sample(frac=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vswS5BgPIpRR"
      },
      "source": [
        "<h2> Pre-Processing </h2>\n",
        "\n",
        "Important pre-processing such as removing the punctuations, converting to lowercase, encoding the textual data to numerical data are done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "mm4koLwuGGJb",
        "outputId": "a4c047b1-bb58-4350-8040-55bfca135db6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                   inputs         tags\n",
              "35                 hows everything there        howami\n",
              "5                                      hi     greeting\n",
              "52            which place do you live in   whereareyou\n",
              "100  what is this organization all about       details\n",
              "115             why should i donate here    statistics\n",
              "..                                    ...          ...\n",
              "105          where do i find your centre       contact\n",
              "63                        how do i donate       donate\n",
              "48            which country are you from   whereareyou\n",
              "62                          how to donate       donate\n",
              "82               steps to join this cause         join\n",
              "\n",
              "[121 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e59ee699-2b28-4d35-85ba-a61a59c727d0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>inputs</th>\n",
              "      <th>tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>hows everything there</td>\n",
              "      <td>howami</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>hi</td>\n",
              "      <td>greeting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>which place do you live in</td>\n",
              "      <td>whereareyou</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>what is this organization all about</td>\n",
              "      <td>details</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>why should i donate here</td>\n",
              "      <td>statistics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>where do i find your centre</td>\n",
              "      <td>contact</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>how do i donate</td>\n",
              "      <td>donate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>which country are you from</td>\n",
              "      <td>whereareyou</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>how to donate</td>\n",
              "      <td>donate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>steps to join this cause</td>\n",
              "      <td>join</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e59ee699-2b28-4d35-85ba-a61a59c727d0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e59ee699-2b28-4d35-85ba-a61a59c727d0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e59ee699-2b28-4d35-85ba-a61a59c727d0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#removing punctuations\n",
        "import string\n",
        "data['inputs'] = data['inputs'].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n",
        "data['inputs'] = data['inputs'].apply(lambda wrd: ''.join(wrd))\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eNahMu32_h1Q"
      },
      "outputs": [],
      "source": [
        "#tokenize the data\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "tokenizer = Tokenizer(num_words=2000)\n",
        "tokenizer.fit_on_texts(data['inputs'])\n",
        "train = tokenizer.texts_to_sequences(data['inputs'])\n",
        "#apply padding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "x_train = pad_sequences(train)\n",
        "\n",
        "#encoding the outputs\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y_train = le.fit_transform(data['tags'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gV-vyDDIpRT"
      },
      "source": [
        "Tensorflow's tokenizer assigns a unique token to each distinct word. and padding is done to get all the data to the same length so as to send it to an rnn layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-VY9ZnyM_65",
        "outputId": "8f2f238c-d773-4991-cfd4-e610608ba95d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8\n"
          ]
        }
      ],
      "source": [
        "input_shape = x_train.shape[1]\n",
        "print(input_shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaXDwXOIAkR4",
        "outputId": "21eb35f3-fe4f-4f1e-d86c-2b27ee9e315f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of unique words :  119\n",
            "output length:  11\n"
          ]
        }
      ],
      "source": [
        "#define vocabulary\n",
        "vocabulary = len(tokenizer.word_index)\n",
        "print(\"number of unique words : \",vocabulary)\n",
        "output_length = le.classes_.shape[0]\n",
        "print(\"output length: \",output_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0C6zisFIpRU"
      },
      "source": [
        "<h2>Neural Network</h2>\n",
        "\n",
        "The Network consist of an embedding layer which is one of the most powerful things in the field of natural language processing. the outputs of the embedding layer is the input of the reccurent layer with lstm gate. then, the output is flattened and a regular dense layer is used with a softmax activation function.\n",
        "\n",
        "The main part is the embedding layer which gives has a corresponding vector for each word in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vaCZkzTEJCd6"
      },
      "outputs": [],
      "source": [
        "#creating the model\n",
        "\n",
        "i = Input(shape=(input_shape,))\n",
        "x = Embedding(vocabulary+1,10)(i)\n",
        "x = LSTM(10,return_sequences=True)(x)\n",
        "x = Flatten()(x)\n",
        "x = Dense(output_length,activation=\"softmax\")(x)\n",
        "model  = Model(i,x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "rqF-km_SK04Q"
      },
      "outputs": [],
      "source": [
        "#compiling the model\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iml1HlsFLUFY",
        "outputId": "7b5e9b65-04f0-48a9-8919-9c275b3dd243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "4/4 [==============================] - 2s 6ms/step - loss: 2.3985 - accuracy: 0.1322\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.3940 - accuracy: 0.1322\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.3891 - accuracy: 0.1570\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.3846 - accuracy: 0.1570\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.3792 - accuracy: 0.1570\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.3737 - accuracy: 0.1570\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.3670 - accuracy: 0.1570\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.3584 - accuracy: 0.1488\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.3496 - accuracy: 0.1488\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.3408 - accuracy: 0.1488\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.3278 - accuracy: 0.1488\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.3150 - accuracy: 0.1488\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.2999 - accuracy: 0.1488\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.2869 - accuracy: 0.1488\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.2707 - accuracy: 0.1488\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.2588 - accuracy: 0.1488\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.2445 - accuracy: 0.1488\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.2314 - accuracy: 0.1488\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.2174 - accuracy: 0.1488\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 2.2055 - accuracy: 0.1653\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.1879 - accuracy: 0.2231\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.1723 - accuracy: 0.2645\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.1538 - accuracy: 0.2810\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.1362 - accuracy: 0.2893\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.1154 - accuracy: 0.2893\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.0937 - accuracy: 0.3058\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.0717 - accuracy: 0.3223\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 2.0464 - accuracy: 0.3140\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.0230 - accuracy: 0.3140\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.9948 - accuracy: 0.3223\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.9676 - accuracy: 0.3140\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.9399 - accuracy: 0.3140\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.9124 - accuracy: 0.3306\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.8842 - accuracy: 0.3140\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.8557 - accuracy: 0.3388\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.8280 - accuracy: 0.3554\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.8009 - accuracy: 0.3636\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.7735 - accuracy: 0.3636\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.7467 - accuracy: 0.4050\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.7208 - accuracy: 0.4298\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.6968 - accuracy: 0.4628\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.6726 - accuracy: 0.4959\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.6481 - accuracy: 0.5041\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.6249 - accuracy: 0.5124\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.6006 - accuracy: 0.5124\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.5781 - accuracy: 0.5289\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.5550 - accuracy: 0.5702\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.5331 - accuracy: 0.5702\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.5096 - accuracy: 0.5785\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.4862 - accuracy: 0.5785\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.4639 - accuracy: 0.5950\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.4415 - accuracy: 0.5950\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.4177 - accuracy: 0.6033\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.3962 - accuracy: 0.6033\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.3754 - accuracy: 0.6116\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.3504 - accuracy: 0.6116\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.3290 - accuracy: 0.6198\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.3058 - accuracy: 0.6198\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.2855 - accuracy: 0.6198\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.2632 - accuracy: 0.6281\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.2423 - accuracy: 0.6281\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.2217 - accuracy: 0.6364\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 1.2019 - accuracy: 0.6364\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1809 - accuracy: 0.6364\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1606 - accuracy: 0.6446\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1408 - accuracy: 0.6612\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1214 - accuracy: 0.6612\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.1020 - accuracy: 0.6612\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0825 - accuracy: 0.6694\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 1.0635 - accuracy: 0.6860\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0485 - accuracy: 0.6942\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0267 - accuracy: 0.7107\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.0089 - accuracy: 0.7025\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9924 - accuracy: 0.6942\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9734 - accuracy: 0.7190\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9564 - accuracy: 0.7521\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.9383 - accuracy: 0.7603\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9225 - accuracy: 0.7603\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.9042 - accuracy: 0.7603\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8891 - accuracy: 0.7851\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8741 - accuracy: 0.7934\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8568 - accuracy: 0.8017\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8421 - accuracy: 0.7934\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8246 - accuracy: 0.8264\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.8105 - accuracy: 0.8182\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7938 - accuracy: 0.8182\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7801 - accuracy: 0.8182\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7638 - accuracy: 0.8182\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7520 - accuracy: 0.8264\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7376 - accuracy: 0.8264\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7228 - accuracy: 0.8182\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7088 - accuracy: 0.8182\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6941 - accuracy: 0.8264\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6809 - accuracy: 0.8264\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6699 - accuracy: 0.8264\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6560 - accuracy: 0.8512\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6440 - accuracy: 0.8512\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.6317 - accuracy: 0.8678\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6187 - accuracy: 0.8678\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.6075 - accuracy: 0.8678\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5956 - accuracy: 0.8926\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5866 - accuracy: 0.8926\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5740 - accuracy: 0.8926\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5611 - accuracy: 0.8926\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5514 - accuracy: 0.8926\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5400 - accuracy: 0.8926\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5292 - accuracy: 0.9008\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5196 - accuracy: 0.9008\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5096 - accuracy: 0.9008\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5004 - accuracy: 0.9008\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4917 - accuracy: 0.9091\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.4810 - accuracy: 0.9091\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4707 - accuracy: 0.9008\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4643 - accuracy: 0.9008\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.9091\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4445 - accuracy: 0.9008\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4360 - accuracy: 0.9174\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.9174\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4212 - accuracy: 0.9339\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4124 - accuracy: 0.9339\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4050 - accuracy: 0.9256\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3982 - accuracy: 0.9256\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3902 - accuracy: 0.9339\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3831 - accuracy: 0.9256\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3763 - accuracy: 0.9339\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3719 - accuracy: 0.9421\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3632 - accuracy: 0.9421\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.3568 - accuracy: 0.9421\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3529 - accuracy: 0.9421\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3469 - accuracy: 0.9504\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3405 - accuracy: 0.9504\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3328 - accuracy: 0.9504\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3271 - accuracy: 0.9504\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3219 - accuracy: 0.9504\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3164 - accuracy: 0.9504\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3119 - accuracy: 0.9587\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3061 - accuracy: 0.9587\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3024 - accuracy: 0.9504\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2985 - accuracy: 0.9587\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2934 - accuracy: 0.9587\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2876 - accuracy: 0.9587\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2827 - accuracy: 0.9587\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2781 - accuracy: 0.9587\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2736 - accuracy: 0.9587\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2681 - accuracy: 0.9587\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2644 - accuracy: 0.9669\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2616 - accuracy: 0.9669\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2568 - accuracy: 0.9669\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2524 - accuracy: 0.9587\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2491 - accuracy: 0.9669\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2449 - accuracy: 0.9669\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2411 - accuracy: 0.9669\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2380 - accuracy: 0.9669\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.2340 - accuracy: 0.9669\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2307 - accuracy: 0.9669\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2279 - accuracy: 0.9669\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2241 - accuracy: 0.9669\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2207 - accuracy: 0.9669\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2181 - accuracy: 0.9669\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2143 - accuracy: 0.9669\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2103 - accuracy: 0.9752\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2077 - accuracy: 0.9752\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2050 - accuracy: 0.9752\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2010 - accuracy: 0.9752\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2002 - accuracy: 0.9752\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1970 - accuracy: 0.9752\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1928 - accuracy: 0.9752\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1902 - accuracy: 0.9752\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1891 - accuracy: 0.9835\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1863 - accuracy: 0.9835\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1840 - accuracy: 0.9835\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1795 - accuracy: 0.9835\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1774 - accuracy: 0.9835\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1746 - accuracy: 0.9835\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1724 - accuracy: 0.9835\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1699 - accuracy: 0.9835\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1673 - accuracy: 0.9835\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1658 - accuracy: 0.9835\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1637 - accuracy: 0.9835\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1609 - accuracy: 0.9835\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1583 - accuracy: 0.9835\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1573 - accuracy: 0.9835\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1544 - accuracy: 0.9835\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1527 - accuracy: 0.9917\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1515 - accuracy: 0.9917\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1482 - accuracy: 0.9917\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1463 - accuracy: 0.9835\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1455 - accuracy: 0.9835\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1433 - accuracy: 0.9835\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1410 - accuracy: 0.9917\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1389 - accuracy: 0.9917\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1373 - accuracy: 0.9917\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1359 - accuracy: 0.9917\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1339 - accuracy: 0.9917\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1322 - accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1307 - accuracy: 0.9917\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1292 - accuracy: 0.9917\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1271 - accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1260 - accuracy: 0.9917\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1244 - accuracy: 0.9917\n"
          ]
        }
      ],
      "source": [
        "#training the model\n",
        "train = model.fit(x_train,y_train,epochs=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mdc0v9RIpRV"
      },
      "source": [
        "<h2> Model Analysis </h2>\n",
        "\n",
        "The model got a perfect accuracy of 100%. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "BcWCycGSLbeB",
        "outputId": "3a8bafe5-fb82-4d30-c901-572bc8fa8a76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5af4dfea50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#plotting model accuracy\n",
        "plt.plot(train.history['accuracy'],label='training set accuracy')\n",
        "plt.plot(train.history['loss'],label='training set loss')\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxZoqlxbIpRV"
      },
      "source": [
        "<h2> Testing </h2>\n",
        "\n",
        "I have also tested the model in a way to mimic a human interacting with a bot and got positive results. however, This was very simple because of the tiny amount of data that I have created. but, the same model can also be used with large amount of data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71ITeJqtfV0s",
        "outputId": "a46790da-3df3-4a94-b22e-9f34f5fc7fb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You : goodbye\n",
            "Nibble :  Take care, Hope u will help us\n"
          ]
        }
      ],
      "source": [
        "#chatting\n",
        "import random\n",
        "\n",
        "\n",
        "while True:\n",
        "  texts_p = []\n",
        "  prediction_input = input('You : ')\n",
        "\n",
        "  #removing punctuation and converting to lowercase\n",
        "  prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n",
        "  prediction_input = ''.join(prediction_input)\n",
        "  texts_p.append(prediction_input)\n",
        "\n",
        "  #tokenizing and padding\n",
        "  prediction_input = tokenizer.texts_to_sequences(texts_p)\n",
        "  prediction_input = np.array(prediction_input).reshape(-1)\n",
        "  prediction_input = pad_sequences([prediction_input],input_shape)\n",
        "\n",
        "  #getting output from model\n",
        "  output = model.predict(prediction_input)\n",
        "  output = output.argmax()\n",
        "\n",
        "  #finding the right tag and predicting\n",
        "  response_tag = le.inverse_transform([output])[0]\n",
        "  print(\"Nibble : \",random.choice(responses[response_tag]))\n",
        "  if response_tag == \"goodbye\":\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YJoGBU0Hn_IZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnW_ZjnnIpRW"
      },
      "source": [
        "<h2> Conclusion </h2>\n",
        "So, This is the Chatbot that I have created with tensorflow2 utilizing the power of embedding matrix.<br>\n",
        "This was created in memory og <b> Going Merry </b> , a ship from a manga called \"One Piece\" which revolves around the story of 5 pirates. "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CFG_Chatbot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}